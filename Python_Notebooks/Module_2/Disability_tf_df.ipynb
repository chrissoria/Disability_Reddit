{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d369ab4-0c2e-4298-b1d7-94aaabe88e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "218b9557-aac9-4932-959a-8e63600109a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../../data')\n",
    "disability = pd.read_csv('disability_sub_top_sm_lemmas.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72de27d7-0ec7-4a8c-86ea-f34a2607449d",
   "metadata": {},
   "source": [
    "## Implementing TF-IDF\n",
    "TF-IDF, short for **term frequency–inverse document frequency**, is a metric that reflects how important a word is to a **document** in a collection or **corpus**. When talking about text datasets, the dataset is called a corpus, and each datapoint is a document. A document can be a post, a paragraph, a webpage, whatever is considered the individual unit of text for a given datset. A **term** is each unique token in a document (we previously also referred to this as **type**). \n",
    "\n",
    "For example in a corpus of sentences, a document might be: `\"I went to New York City in New York state.\"` \n",
    "\n",
    "The processed tokens in that document might be: `[went, new_york, city, new_york, state]`.\n",
    "\n",
    "The document would have four unique terms: `[went, new_york, city, state]`.\n",
    "\n",
    "The TF-IDF value increases proportionally to the number of times a word appears in the document (the term frequency, or TF), and is offset by the number of documents in the corpus that contain the word (the inverse document frequency, or IDF). This helps to adjust for the fact that some words appear more frequently in general – such as articles and prepositions.\n",
    "\n",
    "We won't go into much detail about the math behind calculating the TF-IDF (see the D-Lab Text Analysis workshop videos to see more). The key components to remember are:\n",
    "\n",
    "1. There is one TF-IDF score per unique term and unique document.\n",
    "2. A high TF-IDF score suggests that term is descriptive of that document.\n",
    "3. A low TF-IDF score may be because either the term is not frequent in that document, or that it is frequent in many documents in the dataset - either way, it may not be a good descriptor of that document.\n",
    "\n",
    "The intuition is that if a word occurs many times in one post but rarely in the rest of the corpus, it is probably useful for characterizing that post; conversely, if a word occurs frequently in a post but also occurs frequently in the corpus, it is probably less characteristic of that post.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4eac7237-1d0a-4f9a-848e-8ec39fb0d1ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agree</th>\n",
       "      <th>but</th>\n",
       "      <th>can</th>\n",
       "      <th>cat</th>\n",
       "      <th>does</th>\n",
       "      <th>dog</th>\n",
       "      <th>has</th>\n",
       "      <th>let</th>\n",
       "      <th>likes</th>\n",
       "      <th>my</th>\n",
       "      <th>not</th>\n",
       "      <th>our</th>\n",
       "      <th>out</th>\n",
       "      <th>paws</th>\n",
       "      <th>really</th>\n",
       "      <th>the</th>\n",
       "      <th>we</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   agree  but  can  cat  does  dog  has  let  likes  my  not  our  out  paws  \\\n",
       "0      0    0    0    1     0    0    1    0      0   1    0    0    0     1   \n",
       "1      0    0    1    0     0    1    0    1      0   0    0    0    1     0   \n",
       "2      1    1    0    2     1    1    0    0      1   0    1    1    0     0   \n",
       "\n",
       "   really  the  we  \n",
       "0       0    0   0  \n",
       "1       0    1   1  \n",
       "2       1    2   0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "corpus = [\n",
    "  'My cat has paws.',\n",
    "  'Can we let the dog out?',\n",
    "  'Our dog really likes the cat but the cat does not agree.']\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "#pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "# Use this if your scikit-learn is older\n",
    "pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a2714e4-0d17-4c02-a8a0-7b2c95e2e85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Settings that you use for count vectorizer will go here\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.85,\n",
    "                                   decode_error='ignore',\n",
    "                                   stop_words='english',\n",
    "                                   smooth_idf=True,\n",
    "                                   use_idf=True)\n",
    "\n",
    "# Fit and transform the texts\n",
    "tfidf = tfidf_vectorizer.fit_transform(disability['lemmas'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2dd2899a-3b84-40e1-8c4b-06cd88c7ecf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(tfidf.todense(), columns=tfidf_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78b3a7ea-1d7f-4244-a3a5-dda9ebb50a74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "disability        410.746160\n",
       "like              391.987521\n",
       "people            350.514048\n",
       "work              346.751137\n",
       "know              340.956349\n",
       "                     ...    \n",
       "habitats            0.024578\n",
       "drugstores          0.024578\n",
       "measles             0.024578\n",
       "nineabsolutely      0.024578\n",
       "twothe              0.024578\n",
       "Length: 32131, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df278ce-8c4b-42a6-b255-4f80113450ea",
   "metadata": {},
   "source": [
    "In cosign similarities, 1 = the documents are the same, decreases to 0 the more disimilar they are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f88ff3df-1541-4ac9-be43-5356669664df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14920, 14920)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "similarities = cosine_similarity(tfidf)\n",
    "similarities.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f03659cb-daba-4d87-b513-ba2b90abfa6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.04881839, 0.01612609, ..., 0.01524852, 0.02747433,\n",
       "        0.01840746],\n",
       "       [0.04881839, 1.        , 0.0347358 , ..., 0.02236755, 0.05083116,\n",
       "        0.039858  ],\n",
       "       [0.01612609, 0.0347358 , 1.        , ..., 0.        , 0.01206677,\n",
       "        0.00558479],\n",
       "       ...,\n",
       "       [0.01524852, 0.02236755, 0.        , ..., 1.        , 0.00775328,\n",
       "        0.00607863],\n",
       "       [0.02747433, 0.05083116, 0.01206677, ..., 0.00775328, 1.        ,\n",
       "        0.0038968 ],\n",
       "       [0.01840746, 0.039858  , 0.00558479, ..., 0.00607863, 0.0038968 ,\n",
       "        1.        ]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cc21a876-13cd-4b24-9fa2-8a3a811e1fcf",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'aita' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/89/6bdxzk2j30v5n3wstywbcpg80000gn/T/ipykernel_43071/3065822920.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m similar_df = pd.DataFrame({\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;34m'text'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0maita\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'selftext'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     'score': similarities[doc_idx]}).sort_values('score', ascending=False)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'aita' is not defined"
     ]
    }
   ],
   "source": [
    "similar_df = pd.DataFrame({\n",
    "    'text': aita['selftext'].values,\n",
    "    'score': similarities[doc_idx]}).sort_values('score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2ac19c-f515-4c27-aac1-ec633d02b84d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
